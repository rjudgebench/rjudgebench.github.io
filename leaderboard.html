<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Leaderboard | R-Judge</title>
    <link rel="icon" href="assets/logo.png" type="image/icon type">
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="css/nav.css">
    <link rel="stylesheet" href="css/leaderboard.css">
    <script type="text/javascript" src="javascript/sort-table.js" defer></script>
    <script type="text/javascript" src="javascript/leaderboard-data.js" defer></script>
    <script type="text/javascript" src="javascript/leaderboard.js" defer></script>
</head>

<body>
    <div id="nav">
        <div id="icon">
            <img src="assets/logo.png" id="nav-icon">
            <a class="nav-button" href="https://rjudgebench.github.io/"
                style="margin-left: 2px; font-size: 24px">R-Judge
            </a>
        </div>
        <div>
            <a class="nav-button" href="index.html#home">Home</a>
            <a class="nav-button" href="index.html#dataset">Dataset</a>
            <a class="nav-button" href="index.html#method">Method</a>
            <a class="nav-button" href="index.html#paper">Paper</a>
            <a class="nav-button" href="index.html#code">Code</a>
            <a class="nav-button" href="index.html#citation">Citation</a>
            <a class="nav-button" href="index.html#contact">Contact</a>
            <a class="nav-button" href="leaderboard.html">Leaderboard</a>
            <a class="nav-button" href="explore.html">Explore</a>
        </div>
    </div>
    <div id="body">
        <br><br><br><br>
        <div class="section" style="width: 140%; margin-left: -20%">
            <h1>Leaderboard - R-Judge</h1>
            <p>
                Evaluation of different models on R-Judge dataset.
            </p>
            <p>
                You are invited to contribute your results to the R-Judge Leaderboard. 
                Please send your result scores to <a href="mailto:teenyuan@sjtu.edu.cn" class="ext-link">this email</a> or open a new issue at the <a href="https://github.com/Lordog/R-Judge/issues" class="ext-link">github repository</a>.
                <!-- Please fill in this <a href="https://forms.gle/mRv6CBe1MDh3m47ZA" class="ext-link">Google Form </a> to submit your results. -->
            </p>


            <!-- https://www.cssscript.com/sort-table-header-column/ -->
            <table class="js-sort-table" id="results">
                <thead>
                    <tr>
                        <td class="js-sort-number"><strong>#</strong></td>
                        <td class="js-sort"><strong>Model</strong></td>
                        <td class="js-sort"><strong>Method</strong></td>
                        <td class="js-sort"><strong>F1</strong></td>
                        <td class="js-sort"><strong>Recall</strong></td>
                        <td class="js-sort"><strong>Specificity</strong></td>
                        <td class="js-sort"><strong>Validity</strong></td>
                        <td class="js-sort"><strong>Grade</strong></td>
                        <td class="js-sort"><strong>Effectiveness</strong></td>
                        <td class="js-sort"><strong>Alertness</strong></td>
                    </tr>
                </thead>
                <tbody>
                </tbody>
                
            </table>
            <p>
                <strong>Metrics for Safety Judgment</strong>
                <li><strong>F1</strong>: Overall performance on identifying risks and make safety judgments.</li>
                <li><strong>Recall</strong>: The ratio of successful judgments on unsafe samples, indicating model performance on unsafe samples.</li>
                <li><strong>Specificity</strong>: The ratio of successful judgments on safe samples, indicating model performance on safe samples.</li>
                <li><strong>Validity</strong>: The ratio of samples that the model successfully outputs a single label 'unsafe' or 'safe' as an answer.</li>
                </li>
            </p>
            <p>
                <strong>Metrics for Risk Identification</strong>
                <li><strong>Grade</strong>: Overall performance on risk identification, addition of Effectiveness and Alertness.</li>
                <li><strong>Effectiveness</strong>: Model awareness of how the agent causes safety risks, i.e. the relevance between model-generated analysis and the human-annotated risk description.</li>
                <li><strong>Alertness</strong>: Model awareness of whether there exist risks.</li>
                </li>
            </p>
        </div>
    </div>
</body>

</html>
